{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb464d0",
   "metadata": {},
   "source": [
    "# HRDIC analysis for finding CP parameters\n",
    "\n",
    "Find HRDIC analysis parameters then put into automated code at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2b8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load third-party packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "from defdap import quat\n",
    "from defdap import ebsd\n",
    "from defdap import hrdic\n",
    "from defdap import defaults\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from skimage import io,color\n",
    "from defdap import defaults\n",
    "import HRDIC_vs_CP as hc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebf1b0",
   "metadata": {},
   "source": [
    "## HRDIC slip and strain analysis\n",
    "With many data sets, makes it easier to include values in dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a25b5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slip activaiton\n",
    "#A3_zone1 = 8\n",
    "crop_area = {'A3_zone1':[30, 30, 20, 20],\n",
    "            'A3_zone2':[30,40,10,10],\n",
    "            'A3_zone3':[30,35,10,10]\n",
    "            }\n",
    "\n",
    "dic_homog = {'A3_zone1':[(1765, 335), (738, 215), (1373, 1167), (1550, 1579), (1816, 1790), (1055, 664), (309, 1141), (263, 681)],\n",
    "           'A3_zone2':[(1120, 115), (2089, 703), (583, 1117), (944, 1458), (150, 869), (1508, 871)],\n",
    "           'A3_zone3':[(610, 529), (2083, 216), (1571, 2080), (224, 1958), (243, 986), (850,1394), (1204, 1599)],\n",
    "           'B2_zone1':[(1867, 112), (688, 1112), (1378, 293), (391, 796), (2755, 1534), (2730, 1035), (1933, 1727)]}\n",
    "\n",
    "ebsd_homog = {'A3_zone1':[(402, 352), (335, 343), (376, 410), (388, 439), (405, 452), (356, 373), (307, 407), (303, 376)],\n",
    "           'A3_zone2':[(280, 100), (342, 141), (244, 169), (266, 192), (215, 151), (305, 153)],\n",
    "           'A3_zone3': [(236, 200), (334, 177), (299, 310), (211, 304), (213, 232), (245, 253), (274, 276)],\n",
    "           'B2_zone1':[(292, 131), (218, 198), (261, 143), (198,177), (356, 225), (354, 191), (303, 242)]}\n",
    "\n",
    "dicFilePath ={'A3_zone1':\"../DIC_data/A3/zone_1/take 3/\",\n",
    "             'A3_zone2':\"../DIC_data/A3/zone_2/take3/\",\n",
    "             'A3_zone3':\"../DIC_data/A3/zone_3/take 3/\",\n",
    "             'B2_zone1':\"../DIC_data/B2/take 2/\"}\n",
    "\n",
    "EbsdFilePath={'A3_zone1':'../EBSD_data/CP large area/A3_zone1',\n",
    "              'A3_zone2':'../EBSD_data/CP large area/A3_zone2',\n",
    "              'A3_zone3':'../EBSD_data/CP large area/A3_zone3',\n",
    "              'B2_zone1':'../EBSD_data/CP large area/B2_zone1'}\n",
    "\n",
    "EbsdFlip = {'A3_zone1':False,\n",
    "              'A3_zone2':False,\n",
    "              'A3_zone3':False,\n",
    "              'B2_zone1':True}\n",
    "\n",
    "min_grain ={'A3_zone1':50,\n",
    "           'A3_zone2':50,\n",
    "           'A3_zone3':50,\n",
    "           'B2_zone1':150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63f25383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DaVis 8.4.0 data (dimensions: 2160 x 2214 pixels, sub-window size: 12 x 12 pixels)\n"
     ]
    }
   ],
   "source": [
    "step = '14' # two digits \n",
    "\n",
    "region = 'A3_zone3'\n",
    "#dicFilePath = \"../DIC_data/A3/zone_2\"\n",
    "DicMap = hrdic.Map(dicFilePath[region], \"B000{}.txt\".format(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98150bb0",
   "metadata": {},
   "source": [
    "Optional mask to remove noisy points from data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shear_map = DicMap.eMaxShear\n",
    "#mask = io.imread(dicFilePath[region] +'/02-1.bmp')\n",
    "\n",
    "#plt.imshow(mask)\n",
    "\n",
    "#shear_map[mask < 20 ] = np.nan "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2178cc",
   "metadata": {},
   "source": [
    "Normal HRDIC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ee75b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060839165461511586"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DicMap.setPatternPath('01-1.BMP',1) \n",
    "DicMap.setCrop(xMin=crop_area[region][0], xMax=crop_area[region][1], yMin=crop_area[region][2], yMax=crop_area[region][3])\n",
    "DicMap.setScale(micrometrePerPixel=40/2048)\n",
    "np.mean(DicMap.crop(DicMap.e11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a2f0b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<defdap.plotting.MapPlot at 0x27d35478b80>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DicMap.plotMaxShear(plotColourBar=True, plotScaleBar=True, vmin=0, vmax=0.1)\n",
    "#plt.savefig(output + '{}'.format(step),dpi=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26965705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 606 x 453 pixels, step size: 3.5 um)\n"
     ]
    }
   ],
   "source": [
    "#EbsdFilePath = \"../EBSD_data/CP large area/A3_zone2\"\n",
    "EbsdMap = ebsd.Map(EbsdFilePath[region]) #delete 'cubic'\n",
    "if EbsdFlip[region]:\n",
    "    EbsdMap.rotateData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "942cfb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building quaternion array (0:00:01) \n",
      "Finished finding grain boundaries (0:00:01) \n",
      "Finished finding grains (0:00:01) \n",
      "Finished calculating grain misorientations (0:00:04) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n"
     ]
    }
   ],
   "source": [
    "EbsdMap.buildQuatArray()\n",
    "EbsdMap.findBoundaries(boundDef = 2) #degrees\n",
    "EbsdMap.findGrains(minGrainSize = min_grain[region]) #pixels\n",
    "EbsdMap.calcGrainMisOri(calcAxis = False)\n",
    "EbsdMap.calcAverageGrainSchmidFactors(loadVector=[1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98dc3f",
   "metadata": {},
   "source": [
    "Find the correct homogPoints and then edit the values at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EbsdMap.plotHomog=EbsdMap.plotBandContrastMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DicMap.homogPoints = []\n",
    "EbsdMap.homogPoints = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DicMap.setHomogPoint(display=\"pattern\")\n",
    "DicMap.setHomogPoint(vmax=0.04)\n",
    "#DicMap.setHomogPoint(map_name = \"pattern\")\n",
    "EbsdMap.setHomogPoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DicMap.homogPoints)\n",
    "print(EbsdMap.homogPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd76a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DicMap.homogPoints = [(1765, 335), (738, 215), (1373, 1167), (1550, 1579), (1816, 1790), (1055, 664), (309, 1141), (263, 681)] \n",
    "\n",
    "#EbsdMap.homogPoints = [(402, 352), (335, 343), (376, 410), (388, 439), (405, 452), (356, 373), (307, 407), (303, 376)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4520ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EbsdMap.homogPoints=ebsd_homog[region]\n",
    "DicMap.homogPoints=dic_homog[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "791024bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DicMap.linkEbsdMap(EbsdMap, transformType='polynomial', order = 2)\n",
    "DicMap.linkEbsdMap(EbsdMap, transformType='affine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01fd1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DicMap.plotMaxShear(plotGBs=True, dilateBoundaries=True, plotColourBar=True, plotScaleBar=True, vmin=0, vmax=0.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output + 'DIC_step11',dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9e62790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished finding grains (0:00:00) \n"
     ]
    }
   ],
   "source": [
    "DicMap.findGrains(algorithm='warp')\n",
    "#DicMap.findGrains(algorithm='floodfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cdc78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EbsdMap.plotIPFMap([1,0,0], plotScaleBar=True,plotGB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72c96c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2))\n",
    "DicMap.plotGrainAvMaxShear(vmin=0,vmax=0.03,plotColourBar=True,plotScaleBar=True,plotGBs= True ,dilateBoundaries=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output +'DIC_grain_step11',dpi=1200)#,dpi=1600,figsize=(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b4eeb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DicMap.locateGrainID(vmax=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b0859da",
   "metadata": {},
   "outputs": [],
   "source": [
    "EbsdMap.calcAverageGrainSchmidFactors(loadVector=np.array([1,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a651012",
   "metadata": {},
   "source": [
    "Possible to save slip activity as a text file, in my case the data was in a different format so i needed to write into a spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "206534d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DicMap.runGrainInspector(vmax=0.02,corrAngle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29e75c4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'a'"
     ]
    }
   ],
   "source": [
    "int('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63518aa",
   "metadata": {},
   "source": [
    "## Slip activation \n",
    "\n",
    "Reimport slip data to ccombined and compare between regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82f7878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slip_data_frame = pd.read_csv('Slip_activiation_A3_zone1.csv',skiprows=5)\n",
    "#slip_data_frame = pd.read_csv('Slip_activiation_A3_zone2.csv',skiprows=5)\n",
    "#slip_data_frame = pd.read_csv('Slip_activiation_A3_zone3.csv',skiprows=5)\n",
    "\n",
    "stress_at_step_a3 = np.load('exp_eng_stress_at_image_a3.npy')\n",
    "stress_at_step_b2 = np.load('exp_eng_stress_at_image_b2.npy')\n",
    "\n",
    "num_grains_a3_zone1 = 37\n",
    "num_grains_a3_zone2 = 26\n",
    "num_grains_a3_zone3 = 25\n",
    "\n",
    "num_grains_combined = np.sum([num_grains_a3_zone1,num_grains_a3_zone2,num_grains_a3_zone3])/100\n",
    "#num_grains_combined\n",
    "#slip_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5216a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.9047619 ,   5.71428571,  21.52380952,  63.23809524,\n",
       "       276.38095238, 361.14285714, 446.0952381 , 531.61904762,\n",
       "       619.04761905, 706.0952381 , 786.85714286, 856.19047619,\n",
       "       897.9047619 , 918.66666667, 925.71428571, 936.19047619,\n",
       "       942.0952381 , 947.42857143, 950.0952381 , 954.0952381 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress_at_step_a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49d48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_grain_dict=hc.create_step_grain_dict(slip_data_frame)\n",
    "slip_activation=hc.calculate_slip_activation(step_grain_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26724fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys = sorted(slip_activation.keys())\n",
    "sorted_slip_activation = {key: slip_activation[key] for key in sorted_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44608774",
   "metadata": {},
   "source": [
    "Save into dict format for each region and then reimport together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8dc3b",
   "metadata": {},
   "source": [
    "file_name = \"A3_zone1_slip_activation.pickle\".format(region)\n",
    "with open(file_name, \"wb\") as pickle_file:\n",
    "    pickle.dump(DIC_data, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "273a329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slip_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0afa9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_1 = \"A3_zone1_slip_activation.pickle\"\n",
    "with open(file_name_1, \"rb\") as pickle_file:\n",
    "    slip_activation_A3_zone1 = pickle.load(pickle_file)\n",
    "\n",
    "file_name_2 = \"A3_zone2_slip_activation.pickle\"\n",
    "with open(file_name_2, \"rb\") as pickle_file:\n",
    "    slip_activation_A3_zone2 = pickle.load(pickle_file)\n",
    "\n",
    "file_name_3 = \"A3_zone3_slip_activation.pickle\"\n",
    "with open(file_name_3, \"rb\") as pickle_file:\n",
    "    slip_activation_A3_zone3 = pickle.load(pickle_file)\n",
    "# Now, 'loaded_dict' contains the dictionary that was saved in the Pickle file\n",
    "#print(slip_activation_A3_zone3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "564b4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "slip_activation_zones = [slip_activation_A3_zone1]#, slip_activation_A3_zone2, slip_activation_A3_zone3]\n",
    "slip_activation_combined = hc.combine_slip_activation(slip_activation_zones)\n",
    "#slip_activation_combined = slip_activation_A3_zone1\n",
    "#slip_activation_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c02942d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys = sorted(slip_activation_combined.keys())\n",
    "sorted_slip_activation_combined = {key: slip_activation_combined[key] for key in sorted_keys}\n",
    "#sorted_slip_activation_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a1708c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Basal': [2, 1, 1, 0, 0, 1, 3],\n",
       " 'Prismatic': [0, 2, 2, 3, 7, 1, 0],\n",
       " 'Pyramidal <a>': [0, 3, 2, 5, 7, 1, 1],\n",
       " 'Pyramidal <a+c>': [0, 0, 3, 1, 3, 1, 0],\n",
       " 'ambiguous': [4, 6, 1, 2, 4, 2, 3]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_slip_system_counts = hc.HRDIC_count_slip_systems(sorted_slip_activation_combined)\n",
    "exp_slip_system_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496eafd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Basal': [2, 3, 4, 4, 4, 5, 8], 'Prismatic': [0, 2, 4, 7, 14, 15, 15], 'Pyramidal <a>': [0, 3, 5, 10, 17, 18, 19], 'Pyramidal <a+c>': [0, 0, 3, 4, 7, 8, 8], 'ambiguous': [4, 10, 11, 13, 17, 19, 22]}\n"
     ]
    }
   ],
   "source": [
    "def calculate_cumulative_sum(original_dict):\n",
    "    result_dict = {}\n",
    "    for system, values in original_dict.items():\n",
    "        cumulative_sum = []\n",
    "        running_total = 0\n",
    "        for value in values:\n",
    "            running_total += value\n",
    "            cumulative_sum.append(running_total)\n",
    "        result_dict[system] = cumulative_sum\n",
    "    return result_dict\n",
    "\n",
    "# Example data\n",
    "original_dict = {\n",
    "    'Basal': [2, 1, 1, 0, 0, 1, 3],\n",
    "    'Prismatic': [0, 2, 2, 3, 7, 1, 0],\n",
    "    'Pyramidal <a>': [0, 3, 2, 5, 7, 1, 1],\n",
    "    'Pyramidal <a+c>': [0, 0, 3, 1, 3, 1, 0],\n",
    "    'ambiguous': [4, 6, 1, 2, 4, 2, 3]\n",
    "}\n",
    "\n",
    "result_dict = calculate_cumulative_sum(original_dict)\n",
    "print(result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c12605df",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = list(sorted_slip_activation_combined.keys())\n",
    "categories = list(exp_slip_system_counts.keys())\n",
    "bottom = [0] * len(steps)\n",
    "\n",
    "plt.figure()\n",
    "for category in categories:\n",
    "    plt.bar(steps, exp_slip_system_counts[category], label=category, bottom=bottom)\n",
    "    bottom = [bottom[i] + exp_slip_system_counts[category][i] for i in range(len(steps))]\n",
    "\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Frequency of system')\n",
    "plt.title('Incremental slip activation for combined region')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "348dbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cumulative_counts_dict = hc.calculate_cumulative_counts(sorted_slip_activation_combined)\n",
    "exp_cumulative_counts=hc.flatten_nested_dict(exp_cumulative_counts_dict)\n",
    "#exp_cumulative_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dde26c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a stacked bar chart\n",
    "steps = list(exp_cumulative_counts_dict.keys())\n",
    "categories = list(exp_cumulative_counts.keys())\n",
    "bottom = [0] * len(steps)\n",
    "\n",
    "plt.figure()\n",
    "for category in categories:\n",
    "    plt.bar(steps, exp_cumulative_counts[category], label=category, bottom=bottom)\n",
    "    bottom = [bottom[i] + exp_cumulative_counts[category][i] for i in range(len(steps))]\n",
    "\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Incremental slip activation for combined region')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e98f7c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)#,dpi=800, figsize=(12, 6))\n",
    "\n",
    "# Plot the first graph on the first subplot\n",
    "steps = list(sorted_slip_activation_combined.keys())\n",
    "categories = list(exp_slip_system_counts.keys())\n",
    "bottom = [0] * len(steps)\n",
    "\n",
    "for category in categories:\n",
    "    ax1.bar(steps, exp_slip_system_counts[category], label=category, bottom=bottom)\n",
    "    bottom = [bottom[i] + exp_slip_system_counts[category][i] for i in range(len(steps))]\n",
    "\n",
    "ax1.set_xlabel('Step')\n",
    "ax1.set_ylabel('Frequency of grians')\n",
    "ax1.set_title('Incremental slip activation for combined region')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the second graph on the second subplot\n",
    "bottom = [0] * len(steps)\n",
    "\n",
    "for category in categories:\n",
    "    ax2.bar(steps, exp_cumulative_counts[category], label=category, bottom=bottom)\n",
    "    bottom = [bottom[i] + exp_cumulative_counts[category][i] for i in range(len(steps))]\n",
    "\n",
    "ax2.set_xlabel('Step')\n",
    "ax2.set_ylabel('Frequency of grians')\n",
    "ax2.set_title('Accumulated slip activation for combined region')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plots\n",
    "plt.show()\n",
    "#plt.savefig(output+'/slip_activation_exp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "023fea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3_stress_at_step = []\n",
    "for i in range(len(stress_at_step_a3)):\n",
    "    a3_stress_at_step.append(int(stress_at_step_a3[i]))\n",
    "#a3_stress_at_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "371f63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)#,dpi=800, figsize=(12, 6))\n",
    "\n",
    "# Plot the first graph on the first subplot\n",
    "steps = list(sorted_slip_activation_combined.keys())\n",
    "categories = list(exp_slip_system_counts.keys())\n",
    "bottom = [0] * len(steps)\n",
    "\n",
    "for category in categories:\n",
    "    ax1.bar(steps, exp_slip_system_counts[category], label=category, bottom=bottom)\n",
    "    bottom = [bottom[i] + exp_slip_system_counts[category][i] for i in range(len(steps))]\n",
    "\n",
    "ax1.set_xlabel('Eng stress (MPa)')\n",
    "ax1.set_ylabel('Frequency of system')\n",
    "ax1.set_title('Incremental slip activation for combined region')\n",
    "ax1.legend()\n",
    "\n",
    "# Set custom x-ticks for the first subplot\n",
    "stress_ticks = a3_stress_at_step[5:14] # Define your custom ticks\n",
    "ax1.set_xticks(np.arange(len(custom_ticks))+6)  # Set the tick positions\n",
    "ax1.set_xticklabels(stress_ticks)#, rotation=90)  # Set the tick labels\n",
    "# Plot the second graph on the second subplot\n",
    "bottom = [0] * len(steps)\n",
    "\n",
    "for category in categories:\n",
    "    ax2.bar(steps, exp_cumulative_counts[category], label=category, bottom=bottom)\n",
    "    bottom = [bottom[i] + exp_cumulative_counts[category][i] for i in range(len(steps))]\n",
    "\n",
    "ax2.set_xlabel('Eng Stress (MPa)')\n",
    "ax2.set_ylabel('Frequency of system')\n",
    "ax2.set_title('Accumulated slip activation for combined region')\n",
    "ax2.legend()\n",
    "\n",
    "stress_ticks = a3_stress_at_step[5:14] # Define your custom ticks\n",
    "ax2.set_xticks(np.arange(len(custom_ticks))+6)  # Set the tick positions\n",
    "ax2.set_xticklabels(stress_ticks)#, rotation=90)  # Set the tick labels\n",
    "# Plot the second graph on the second subplot\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plots\n",
    "#plt.show()\n",
    "#plt.savefig(output + 'Slip_activation_exp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba70385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from defdap import defaults\n",
    "#defaults['crystal_ortho_conv'] = 'hkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12a1d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grainOris = [grain.ebsdGrain.refOri for grain in DicMap]\n",
    "plot = quat.Quat.plotIPF(grainOris, direction=[1,0,0], symGroup='hexagonal', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f735b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "slip_activation = slip_activation_A3_zone2\n",
    "#slip_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "375bd746",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in slip_activation.items():\n",
    "    # Check if the value is a dictionary\n",
    "    if isinstance(value, dict):\n",
    "        # Iterate through the inner dictionary\n",
    "        for inner_key, inner_value in value.items():\n",
    "            # Check if the value is a list with at least one element\n",
    "            if isinstance(inner_value, list) and len(inner_value) >= 1:\n",
    "                # Modify the list to keep only the first element (string)\n",
    "                slip_activation[key][inner_key] = inner_value[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b2d94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "\n",
    "# Iterate over the steps in reverse order\n",
    "for step in range(max(slip_activation.keys()), -1, -1):\n",
    "    new_grains = {}\n",
    "    for prev_step in range(step + 1):\n",
    "        for grain, value in slip_activation[prev_step].items():\n",
    "            new_grains.setdefault(grain, value)  # Corrected order\n",
    "    new_dict[step] = new_grains\n",
    "\n",
    "sorted_dict = {k: v for k, v in sorted(new_dict.items(), key=lambda item: item[0], reverse=False)}\n",
    "sorted_nested_dict = {step: {k: v for k, v in sorted(sub_dict.items())} for step, sub_dict in sorted_dict.items()}\n",
    "\n",
    "#print(sorted_nested_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854298a",
   "metadata": {},
   "source": [
    "new_dict = {}\n",
    "\n",
    "# Iterate over the steps in reverse order\n",
    "for step in range(max(original_dict.keys()), -1, -1):\n",
    "    new_grains = {}\n",
    "    for prev_step in range(step + 1):\n",
    "        for grain, value in original_dict[prev_step].items():\n",
    "            if grain not in new_grains or new_grains[grain] == 'ambiguous':\n",
    "                new_grains[grain] = value\n",
    "    new_dict[step] = new_grains\n",
    "\n",
    "sorted_dict = {k: v for k, v in sorted(new_dict.items(), key=lambda item: item[0], reverse=False)}\n",
    "sorted_nested_dict = {step: {k: v for k, v in sorted(sub_dict.items())} for step, sub_dict in sorted_dict.items()}\n",
    "\n",
    "print(sorted_nested_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15c1e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_nested_dict\n",
    "#sorted_nested_dict[int(steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "035ded34",
   "metadata": {},
   "outputs": [],
   "source": [
    "output ='../results/IPF/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14891309",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(4,3))\n",
    "\n",
    "markersize=50\n",
    "quat.Quat.plotIPF(allgrains, [1,0,0], 'hexagonal', color='0.8', marker='o', s=markersize-20, ax=ax,label='All grains')  \n",
    "quat.Quat.plotIPF(baorilist, [1,0,0], 'hexagonal' , marker='h', s=markersize, ax=ax,label='Basal') # c='b'\n",
    "quat.Quat.plotIPF(prorilist, [1,0,0], 'hexagonal', marker='s', s=markersize, ax=ax,label='Prismatic') #  c='g',\n",
    "quat.Quat.plotIPF(py_aorilist, [1,0,0], 'hexagonal',  marker='^', s=markersize, ax=ax,label='Pyramidal <a>') #  c='r',\n",
    "quat.Quat.plotIPF(py_acorilist, [1,0,0], 'hexagonal',  marker='d', s=markersize, ax=ax,label='Pyramidal <a+c>') # \n",
    "quat.Quat.plotIPF(ambiglist, [1,0,0], 'hexagonal',  marker='*', s=markersize, ax=ax,label='Ambiguous') #c='m', \n",
    "\n",
    "plt.legend()\n",
    "output ='../results/IPF/'\n",
    "f.tight_layout()\n",
    "f.savefig(output + 'A3_zone2_step{}_ipf.png'.format(str(step)), dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c39df",
   "metadata": {},
   "source": [
    "new_dict = {}\n",
    "\n",
    "# Iterate over the steps in reverse order\n",
    "for step in range(max(original_dict.keys()), -1, -1):\n",
    "    new_grains = {}\n",
    "    for prev_step in range(step + 1):\n",
    "        for grain, value in original_dict[prev_step].items():\n",
    "            new_grains.setdefault(value, grain)\n",
    "    new_dict[step] = new_grains\n",
    "sorted_dict = {k: v for k, v in sorted(new_dict.items(), key=lambda item: item[0], reverse=False)}\n",
    "\n",
    "print(sorted_dict[14])\n",
    "\n",
    "#print(new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c61b51",
   "metadata": {},
   "source": [
    "prorilist = []; pyorilist = []; baorilist = []; multorilist = [];  allgrains=[]; \n",
    "\n",
    "for idx, grain in enumerate(DicMap):\n",
    "    \n",
    "    try:\n",
    "        system = grain.groupsList[0][2]\n",
    "    except IndexError:\n",
    "        continue\n",
    "        \n",
    "    allgrains.append(grain.ebsdGrain.refOri)\n",
    "        \n",
    "    \n",
    "    \n",
    "    if len(system)>1 or system==[]:\n",
    "        i=1\n",
    "    else: \n",
    "        if system == [0]:\n",
    "            baorilist.append(grain.ebsdGrain.refOri)\n",
    "        if system == [1] or system == [2] or system == [3]:\n",
    "            prorilist.append(grain.ebsdGrain.refOri)\n",
    "        if system == [4] or system == [5] or system == [6] or system == [7] or system == [8] or system == [9]:\n",
    "            pyorilist.append(grain.ebsdGrain.refOri)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(4,3))\n",
    "\n",
    "markersize=40\n",
    "quat.Quat.plotIPF(allgrains, [1,0,0], 'hexagonal', c='b', marker='o', s=markersize, ax=ax,label='All grains')  \n",
    "quat.Quat.plotIPF(allgrains, [1,0,0], 'hexagonal', c='0.9', marker='o', s=markersize, ax=ax,label='All grains')  \n",
    "quat.Quat.plotIPF(multorilist, [1,0,0], 'hexagonal', c='0.4', marker='o', s=markersize, ax=ax,label='Multi slip')\n",
    "quat.Quat.plotIPF(prorilist, [1,0,0], 'hexagonal', c='g', marker='s', s=markersize, ax=ax,label='Prismatic only')\n",
    "quat.Quat.plotIPF(pyorilist, [1,0,0], 'hexagonal', c='r', marker='^', s=markersize, ax=ax,label='Pyramidal only')\n",
    "quat.Quat.plotIPF(baorilist, [1,0,0], 'hexagonal', c='b', marker='h', s=markersize, ax=ax,label='Basal only')\n",
    "  \n",
    "# quat.Quat.plotIPF(allgrains, [1,0,0], 'hexagonal', marker='o', s=markersize, ax=ax)  \n",
    "# quat.Quat.plotIPF(multorilist, [1,0,0], 'hexagonal', marker='o', s=markersize, ax=ax)  \n",
    "# quat.Quat.plotIPF(prorilist, [1,0,0], 'hexagonal', marker='o', s=markersize, ax=ax)\n",
    "# quat.Quat.plotIPF(pyorilist, [1,0,0], 'hexagonal', marker='o', s=markersize, ax=ax)\n",
    "# quat.Quat.plotIPF(baorilist, [1,0,0], 'hexagonal', marker='o', s=markersize, ax=ax)\n",
    "plt.legend()\n",
    "\n",
    "f.tight_layout()\n",
    "#f.savefig(output + 'B2_zone1_step13.png', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe5933",
   "metadata": {},
   "source": [
    "EbsdFilePath = \"../EBSD_data/DIC actual area/A3_zone1\"\n",
    "EbsdMap = ebsd.Map(EbsdFilePath) #delete 'cubic'\n",
    "#EbsdMap.rotateData()\n",
    "EbsdMap.findGrains()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ebd26",
   "metadata": {},
   "source": [
    "allgrains = []\n",
    "for grain in EbsdMap:\n",
    "    grain.calcAverageOri()\n",
    "    allgrains.append(grain.refOri)\n",
    "#np.save(\"a3_z3_grainAvOris.npy\",allgrains)\n",
    "##### Plot all the grain orientations in the map\n",
    "quat.Quat.plotIPF(allgrains, [1, 0, 0], EbsdMap.crystalSym, marker='o', s=10)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "267fe836",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'orix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [135]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01morix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot\n\u001b[0;32m      2\u001b[0m ckey_m3m \u001b[38;5;241m=\u001b[39m plot\u001b[38;5;241m.\u001b[39mIPFColorKeyTSL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm-3m\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m fig \u001b[38;5;241m=\u001b[39m ckey_m3m\u001b[38;5;241m.\u001b[39mplot(return_figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Returns a Matplotlib figure\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'orix'"
     ]
    }
   ],
   "source": [
    "from orix import plot\n",
    "ckey_m3m = plot.IPFColorKeyTSL(\"m-3m\")\n",
    "fig = ckey_m3m.plot(return_figure=True)  # Returns a Matplotlib figure\n",
    "fig.savefig(\"ckey_m3m.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2aeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5114a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d159ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f87e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0586ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "grain_ID = []\n",
    "DIC_ESS = []\n",
    "grain_size = []\n",
    "DIC_e11 = []\n",
    "for k in range(0,len(DicMap.grainList)):\n",
    "    grain_ID.append(DicMap[k].ebsdGrain.grainID)\n",
    "    DIC_ESS.append(np.mean(DicMap[k].maxShearList))\n",
    "    grain_size.append(len(DicMap[k].maxShearList))\n",
    "    #DIC_e11.append(DicMap.calcGrainAv(DicMap.crop(DicMap.e11)))\n",
    "DIC_e11=(DicMap.calcGrainAv(DicMap.crop(DicMap.e11)))\n",
    "DIC_e22=(DicMap.calcGrainAv(DicMap.crop(DicMap.e22)))\n",
    "DIC_e12=(DicMap.calcGrainAv(DicMap.crop(DicMap.e12)))\n",
    "DIC_shear_strain = (( np.mean(DIC_e11) - np.mean(DIC_e22) )**2/2 + np.mean(DIC_e12)**2  )**0.5 \n",
    "DIC_shear_strain\n",
    "#print(EBSD_DIC_grains)\n",
    "#print(DIC_grain_strain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e430633",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_shear_strain = calculate_std_shear_strain(DIC_e11, DIC_e22, DIC_e12)\n",
    "print(\"Standard Deviation of Shear Strain:\", std_shear_strain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39756e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the length of the array 'L'\n",
    "L = 10  # Replace with your desired length\n",
    "\n",
    "# Replace 'DIC_std_shear_strain' with your actual value\n",
    "DIC_std_shear_strain = 0.002  # Replace with your value\n",
    "\n",
    "# Create an array of length 'L' with the same value as 'DIC_std_shear_strain'\n",
    "array_of_values = np.full((L,), DIC_std_shear_strain)\n",
    "array_of_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd35fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_11 = np.column_stack((grain_ID, grain_size, DIC_ESS,DIC_e11,DIC_e22,DIC_e22))\n",
    "df=pd.DataFrame(step_11)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DicMap.calcGrainAv(DicMap.crop(DicMap.e11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.full((len(DicMap.grainList,),), std_shear_strain)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4d63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:01) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:01) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:01) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:01) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:01) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:01) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Loaded DaVis 8.4.0 data (dimensions: 2169 x 2128 pixels, sub-window size: 12 x 12 pixels)\n",
      "Starting loading EBSD data..\n",
      "Unknown field in file with key 51. Assumming float32 data.\n",
      "Loaded EBSD data (dimensions: 554 x 313 pixels, step size: 3.5 um)\n",
      "Finished building quaternion array (0:00:00) \n",
      "Finished finding grain boundaries (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain misorientations (0:00:02) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n",
      "Finished finding grains (0:00:00) \n",
      "Finished calculating grain average Schmid factors (0:00:00) \n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "from defdap import quat\n",
    "from defdap import ebsd\n",
    "from defdap import hrdic\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "##################################################################################################################\n",
    "#SAMPLE PARAMETERS\n",
    "region='A3_zone2' #change file path\n",
    "DIC_data = {}\n",
    "resolution = 40/2048\n",
    "DIC_mean_shear_strain = []\n",
    "DIC_std_shear_strain  = []\n",
    "output =\"../results/{}/\".format(region)\n",
    "plot_maps = True\n",
    "#slip activaiton\n",
    "#A3_zone1 = 8\n",
    "crop_area = {'A3_zone1':[30, 30, 20, 20],\n",
    "            'A3_zone2':[30,40,10,10],\n",
    "            'A3_zone3':[30,35,10,10]\n",
    "            }\n",
    "\n",
    "dic_homog = {'A3_zone1':[(1765, 335), (738, 215), (1373, 1167), (1550, 1579), (1816, 1790), (1055, 664), (309, 1141), (263, 681)],\n",
    "           'A3_zone2':[(1120, 115), (2089, 703), (583, 1117), (944, 1458), (150, 869), (1508, 871)],\n",
    "           'A3_zone3':[(610, 529), (2083, 216), (1571, 2080), (224, 1958), (243, 986), (850,1394), (1204, 1599)],\n",
    "           'B2_zone1':[(1867, 112), (688, 1112), (1378, 293), (391, 796), (2755, 1534), (2730, 1035), (1933, 1727)]}\n",
    "\n",
    "ebsd_homog = {'A3_zone1':[(402, 352), (335, 343), (376, 410), (388, 439), (405, 452), (356, 373), (307, 407), (303, 376)],\n",
    "           'A3_zone2':[(280, 100), (342, 141), (244, 169), (266, 192), (215, 151), (305, 153)],\n",
    "           'A3_zone3': [(236, 200), (334, 177), (299, 310), (211, 304), (213, 232), (245, 253), (274, 276)],\n",
    "           'B2_zone1':[(292, 131), (218, 198), (261, 143), (198,177), (356, 225), (354, 191), (303, 242)]}\n",
    "\n",
    "dicFilePath ={'A3_zone1':\"../DIC_data/A3/zone_1/take 3/\",\n",
    "             'A3_zone2':\"../DIC_data/A3/zone_2/take3/\",\n",
    "             'A3_zone3':\"../DIC_data/A3/zone_3/take 3/\",\n",
    "             'B2_zone1':\"../DIC_data/B2/take 2/\"}\n",
    "\n",
    "EbsdFilePath={'A3_zone1':'../EBSD_data/CP large area/A3_zone1',\n",
    "              'A3_zone2':'../EBSD_data/CP large area/A3_zone2',\n",
    "              'A3_zone3':'../EBSD_data/CP large area/A3_zone3',\n",
    "              'B2_zone1':'../EBSD_data/CP large area/B2_zone1'}\n",
    "\n",
    "EbsdFlip = {'A3_zone1':False,\n",
    "              'A3_zone2':False,\n",
    "              'A3_zone3':False,\n",
    "              'B2_zone1':True}\n",
    "\n",
    "min_grain ={'A3_zone1':50,\n",
    "           'A3_zone2':50,\n",
    "           'A3_zone3':50,\n",
    "           'B2_zone1':150}\n",
    "##################################################################################################################\n",
    "#IMPORT DIC DATA\n",
    "for step in np.arange(1,15): #index from 1\n",
    "    if step <10:\n",
    "        DicMap = hrdic.Map(dicFilePath[region], \"B0000{}.txt\".format(step))\n",
    "    else:\n",
    "        DicMap = hrdic.Map(dicFilePath[region], \"B000{}.txt\".format(step))\n",
    "    \n",
    "###################################################################################################################\n",
    "#LINK DIC AND EBSD \n",
    "    DicMap.setPatternPath('01-1.BMP',1) \n",
    "    DicMap.setCrop(xMin=crop_area[region][0], xMax=crop_area[region][1], yMin=crop_area[region][2], yMax=crop_area[region][3])\n",
    "    DicMap.setScale(micrometrePerPixel=resolution)\n",
    "\n",
    "    EbsdMap = ebsd.Map(EbsdFilePath[region]) #delete 'cubic'\n",
    "    \n",
    "    if EbsdFlip[region]:\n",
    "        EbsdMap.rotateData()\n",
    "\n",
    "    EbsdMap.buildQuatArray()\n",
    "    EbsdMap.findBoundaries(boundDef = 2) #degrees\n",
    "    EbsdMap.findGrains(minGrainSize = min_grain[region]) #pixels\n",
    "    EbsdMap.calcGrainMisOri(calcAxis = False)\n",
    "    EbsdMap.calcAverageGrainSchmidFactors(loadVector=[1,0,0])\n",
    "    \n",
    "    DicMap.homogPoints = dic_homog[region]\n",
    "    EbsdMap.homogPoints = ebsd_homog[region]\n",
    "\n",
    "    #DicMap.linkEbsdMap(EbsdMap, transformType='polynomial', order = 2)\n",
    "    DicMap.linkEbsdMap(EbsdMap, transformType='affine')\n",
    "\n",
    "    DicMap.findGrains(algorithm='warp')\n",
    "    EbsdMap.calcAverageGrainSchmidFactors(loadVector=np.array([1,0,0]))\n",
    "#########################################################################################################################\n",
    "#PLOT MAPS\n",
    "    if plot_maps: \n",
    "        DicMap.plotGrainAvMaxShear(vmin=0,vmax=0.015,plotColourBar=True,plotScaleBar=True,plotGBs= True ,dilateBoundaries=True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output + 'Grain_avg_ESS_DIC_{}'.format(step),dpi=1600)\n",
    "        plt.close()\n",
    "        DicMap.plotMaxShear(plotGBs=True, dilateBoundaries=True, plotColourBar=True, plotScaleBar=True, vmin=0, vmax=0.015)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output + 'ESS_DIC_{}'.format(step),dpi=1600)\n",
    "        plt.close()\n",
    "#######################################################################################################################\n",
    "#ANALYSIS STRAINS\n",
    "    grain_ID = []\n",
    "    DIC_ESS = []\n",
    "    grain_size = []\n",
    "    DIC_e11 =[]\n",
    "    DIC_e22 =[]\n",
    "    DIC_e12 =[]\n",
    "    for k in range(0,len(DicMap.grainList)):\n",
    "        grain_ID.append(DicMap[k].ebsdGrain.grainID)\n",
    "        grain_size.append(len(DicMap[k].maxShearList)*resolution)\n",
    "    \n",
    "    DIC_e11=(DicMap.calcGrainAv(DicMap.crop(DicMap.e11)))\n",
    "    DIC_e22=(DicMap.calcGrainAv(DicMap.crop(DicMap.e22)))\n",
    "    DIC_e12=(DicMap.calcGrainAv(DicMap.crop(DicMap.e12)))\n",
    "    shear_strain=[]\n",
    "    for i in range(len(DIC_e11)):    \n",
    "        shear_strain.append( (( (DIC_e11[i]) - (DIC_e22[i]) )**2/2 + (DIC_e12[i])**2  )**0.5 )\n",
    "    DIC_mean_shear_strain = np.mean(shear_strain)\n",
    "    DIC_std_shear_strain = np.std(shear_strain)\n",
    "#####################################################################################################################\n",
    "#EXPORT DATA\n",
    "    \n",
    "    #DIC_data['step_{}'.format(str(step))]=np.column_stack((grain_ID, grain_size, DIC_e11,shear_strain))\n",
    "    DIC_data['step_{}'.format(str(step))] = {'grain_ID':grain_ID,'grain_size ($\\mu m^2$)':grain_size,'DIC_e11':DIC_e11,'DIC_shear_strain':shear_strain}\n",
    "file_name = \"{}_strain_DIC.pickle\".format(region)\n",
    "with open(file_name, \"wb\") as pickle_file:\n",
    "    pickle.dump(DIC_data, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b494d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"A3_zone2_strain_DIC.pickle\"\n",
    "with open(file_name, \"rb\") as pickle_file:\n",
    "    strain_comparison = pickle.load(pickle_file)\n",
    "\n",
    "# Now, 'loaded_dict' contains the dictionary that was saved in the Pickle file\n",
    "print(strain_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4aaa08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f9bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
